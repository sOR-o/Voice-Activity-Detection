{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fceeb0b-b1f8-4a81-b0fb-61da197eda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from funasr import AutoModel\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from speechbrain.inference.VAD import VAD\n",
    "import seaborn as sns\n",
    "from pyannote.core import Segment\n",
    "from pyannote.audio import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a349dc-c43b-42bf-8e9b-924d6db538c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silero\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "torch.hub.set_dir('../models/.cache')\n",
    "model_silero, utils_silero = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True,\n",
    "                              onnx=False)\n",
    "\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils_silero\n",
    "\n",
    " # pyannote\n",
    "pipeline = Pipeline.from_pretrained (\n",
    "        \"pyannote/voice-activity-detection\",\n",
    "         use_auth_token=\"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\", # Once while downloading the model\n",
    "        cache_dir=\"../models/.cache\"\n",
    "        )\n",
    "\n",
    "# speechbrain\n",
    "vad = VAD.from_hparams(\n",
    "        source=\"speechbrain/vad-crdnn-libriparty\",\n",
    "        savedir=\"../models/.cache\"  # Save the model in a cache folder\n",
    ")\n",
    "\n",
    "# funasr\n",
    "model_funasr = AutoModel(model=\"fsmn-vad\", model_revision=\"v2.0.4\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68db8c2b-4d0f-43de-9200-73c1ce1fc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sgeadmin/Saurabh_Kushwaha/vad/\")\n",
    "\n",
    "from helper import vad_inference_pyannote, print_timestamps_pyannote, run_vad_on_noisy_audio_pyannote, visualize_metrics_vs_SNR_pyannote\n",
    "from helper import vad_inference_funasr, convert_to_timestamps_funasr, run_vad_on_noisy_audio_funasr, visualize_metrics_vs_SNR_funasr\n",
    "from helper import vad_inference_silero, print_timestamps_silero, run_vad_on_noisy_audio_silero, visualize_metrics_vs_SNR_silero\n",
    "from helper import vad_inference_speechbrain, print_timestamps_speechbrain, run_vad_on_noisy_audio_speechbrain, visualize_metrics_vs_SNR_speechbrain\n",
    "from helper.vad import parse_annotations_file_bh, evaluate_vad, add_noise, save_audio, plot_SNR, extract_metrics, visualize_all_metrics, evaluate_vad_cmatrix, plot_confusion_matrices, get_file_paths, read_path, parse_annotations_file, average_metrics, show_vad_matrix_bh, save_results_to_csv, extract_speech_segments, count_continuous_zeros_after_start_segments, count_continuous_ones_after_end_segments, calculate_fec, calculate_msc, calculate_over, calculate_nds, save_results_to_csv1, show_vad_metrics_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5b5a2de-ae76-4824-be48-c1a7d86f5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_directory = \"/home/sgeadmin/Saurabh_Kushwaha/vad/data/bh_dataset/bh_audios\"\n",
    "label_directory = \"/home/sgeadmin/Saurabh_Kushwaha/vad/data/bh_dataset/bh_labels\"\n",
    "\n",
    "\n",
    "audio_paths, label_paths = read_path(wav_directory, label_directory)\n",
    "audio_paths.sort()\n",
    "label_paths.sort()\n",
    "annotated_segments = [parse_annotations_file_bh(label_path) for label_path in label_paths] \n",
    "\n",
    "label_paths = label_paths[:20]\n",
    "audio_paths = audio_paths[:20]\n",
    "annotated_segments = annotated_segments[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d64b3a38-fc3a-401f-b6cf-973d22cb9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pyannote = []\n",
    "result_silero = []\n",
    "result_speechbrain = []\n",
    "result_funasr = []\n",
    "cmatrix_pyannote = []\n",
    "cmatrix_silero = []\n",
    "cmatrix_speechbrain = []\n",
    "cmatrix_funasr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52254a6-c627-4825-b44b-8a1193b556b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(audio_paths)):\n",
    "    pyannote = vad_inference_pyannote(pipeline, audio_paths[i])\n",
    "    funasr = vad_inference_funasr(audio_paths[i], model_funasr)\n",
    "    silero = vad_inference_silero(audio_paths[i], model_silero, utils_silero, sampling_rate=SAMPLING_RATE)\n",
    "    speechbrain = vad_inference_speechbrain(audio_paths[i], vad)\n",
    "\n",
    "    pyannote = print_timestamps_pyannote(pyannote)\n",
    "    funasr = convert_to_timestamps_funasr(funasr)\n",
    "    silero = print_timestamps_silero(silero)\n",
    "    speechbrain = print_timestamps_speechbrain(speechbrain)\n",
    "\n",
    "    cmatrix_pyannote.append(evaluate_vad_cmatrix(pyannote, annotated_segments[i]))\n",
    "    cmatrix_silero.append(evaluate_vad_cmatrix(silero, annotated_segments[i]))\n",
    "    cmatrix_speechbrain.append(evaluate_vad_cmatrix(speechbrain, annotated_segments[i]))\n",
    "    cmatrix_funasr.append(evaluate_vad_cmatrix(funasr, annotated_segments[i]))\n",
    "\n",
    "    result_pyannote.append(evaluate_vad(pyannote, annotated_segments[i]))\n",
    "    result_silero.append(evaluate_vad(silero, annotated_segments[i]))\n",
    "    result_speechbrain.append(evaluate_vad(speechbrain, annotated_segments[i]))\n",
    "    result_funasr.append(evaluate_vad(funasr, annotated_segments[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a6535a-7d92-49bf-8d88-1e23c278177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_funasr = average_metrics(result_funasr)\n",
    "avg_pyannote = average_metrics(result_pyannote)\n",
    "avg_speechbrain = average_metrics(result_speechbrain)\n",
    "avg_silero = average_metrics(result_silero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcba32b-dd3a-43b0-82b0-e43ac914df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_vad_matrix_bh(avg_pyannote, avg_funasr, avg_silero, avg_speechbrain, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06afa1-ba23-4f07-b6c0-ad4457765cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"vad-matrix.csv\"\n",
    "model_names = ['Pyannote', 'FunASR', 'Silero', 'SpeechBrain']\n",
    "\n",
    "# Save CSV file\n",
    "save_results_to_csv(\n",
    "    [result_pyannote, result_funasr, result_silero, result_speechbrain],\n",
    "    model_names,\n",
    "    output_file,\n",
    "    label_paths\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
